{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dhlab.nbtext as nb\n",
    "from dhlab.nbtokenizer import tokenize\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "import zipfile\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import zipfile\n",
    "import re\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "## Korpuset kommer som en zip\n",
    "\n",
    "def get_files_from_zip(document):\n",
    "    \"\"\"Find all documents in .zip\"\"\"\n",
    "    import sys\n",
    "    import zipfile\n",
    "    import re\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    with zipfile.ZipFile(document, 'r') as zfp:\n",
    "           n = zfp.namelist()\n",
    "    return n\n",
    "\n",
    "def file_contents(name, zipfolder):\n",
    "    \n",
    "    with zipfile.ZipFile(zipfolder, 'r') as zfp:\n",
    "        try:\n",
    "            with zfp.open(name) as fp:\n",
    "                soup = fp.read()\n",
    "        except:\n",
    "            print('problemer', name)\n",
    "    return soup\n",
    "\n",
    "def extract_text(file, zipfolder):\n",
    "    text = []\n",
    "    soup = BeautifulSoup(file_contents(file, zipfolder), 'html.parser')\n",
    "    for node in soup.find_all('div', {\"type\":\"chapter\", \"subtype\":\"source\"}):\n",
    "        for p in node.find_all(['p', 'head']) :\n",
    "            text.append(tokenize(p.text))\n",
    "    return text\n",
    "\n",
    "def extract_text_as_string(file, zipfolder):\n",
    "    text = []\n",
    "    soup = BeautifulSoup(file_contents(file, zipfolder), 'html.parser')\n",
    "    for node in soup.find_all('div', {\"type\":\"chapter\", \"subtype\":\"source\"}):\n",
    "        for p in node.find_all(['p', 'head']) :\n",
    "            text.append(p.text)\n",
    "    return text\n",
    "\n",
    "#Se på en og en fil i første omgang, for å ut teksten\n",
    "\n",
    "def make_corpus(zipfolder, extraction = extract_text):\n",
    "    texts = dict()\n",
    "    for f in get_files_from_zip(zipfolder):\n",
    "        texts[f] = extraction(f, zipfolder)\n",
    "    return texts\n",
    "\n",
    "\n",
    "\n",
    "def make_dtm(texts):\n",
    "    dtm = pd.DataFrame()\n",
    "    freqs = dict()\n",
    "    for text in texts.keys():\n",
    "        print(text)\n",
    "        c = Counter()\n",
    "        for p in texts[text]:\n",
    "            c.update(p)\n",
    "        freqs[text] = nb.frame(c, text)\n",
    "    dtm = pd.concat([freqs[text] for text in freqs.keys()], axis=1, sort=False)\n",
    "    return dtm\n",
    "\n",
    "def sublist(phrase, alist):\n",
    "    if phrase == [] or alist == []:\n",
    "        return None\n",
    "    found = None\n",
    "    try:\n",
    "        ix = alist.index(phrase[0])\n",
    "        searching = True\n",
    "        while ix < len(alist) and searching == True:\n",
    "            if alist[ix: ix + len(phrase)] == phrase:\n",
    "                if found == None:\n",
    "                    found = [ix]\n",
    "                else:\n",
    "                    found.append(ix)\n",
    "                try:\n",
    "                    sublist = alist[ix + len(phrase):]\n",
    "                    ix += sublist.index(phrase[0])\n",
    "                except:\n",
    "                    searching = False\n",
    "            else:\n",
    "                ix += 1\n",
    "    except:\n",
    "        True\n",
    "    return found\n",
    "\n",
    "def konk0(phrase, corpus):    \n",
    "    return [[p,sublist(phrase, p)] for t in corpus for p in t ]\n",
    "\n",
    "def coll(phrase, corpus, before = 5, after = 5):\n",
    "    \"\"\"Determine collocation within corpus if before and after are both zero the whole paragraph is returned\"\"\"\n",
    "    \n",
    "    collocation = Counter()\n",
    "    all_of_paragraph = before == 0 and after == 0\n",
    "    \n",
    "    for t in corpus:\n",
    "        for avsnitt in corpus[t]:\n",
    "            res = sublist(phrase, avsnitt)\n",
    "            if res != None:\n",
    "                for i in res:\n",
    "                    #print(i, len(phrase), avsnitt[max(i - before - 1, 0): i + len(phrase) + 1 + after])\n",
    "                    collocation.update(avsnitt[max(i - before - 1, 0): i + len(phrase) + 1 + after])\n",
    "    return collocation\n",
    "\n",
    "\n",
    "\n",
    "def konk(phrase, corpus):\n",
    "    finds = dict()\n",
    "    # for hver tekst i korpuset\n",
    "    for t in corpus:\n",
    "        finds[t] = []\n",
    "        # hent avsnittene i korpuset\n",
    "        for i, avsnitt in enumerate(corpus[t]):\n",
    "            res = sublist(phrase, avsnitt)\n",
    "            if res != None:\n",
    "                finds[t].append((i, res))\n",
    "    return finds\n",
    "\n",
    "\n",
    "\n",
    "def konk_regex(regex, korpus, before=30, after=30, colour='red'):\n",
    "    res = []\n",
    "    for t in korpus:\n",
    "        found = []\n",
    "        for i, avsnitt in enumerate(korpus[t]):\n",
    "\n",
    "            s = re.search(regex, avsnitt)\n",
    "            if s != None:\n",
    "                p1 = s.span()[0]\n",
    "                p2 = s.span()[1]\n",
    "                found.append(str(i) + \": \" + avsnitt.replace(avsnitt[p1:p2], \"<span style='color:{c}'>\".format(c=colour) + avsnitt[p1:p2] + \"</span>\")[max(0,p1 - before): p2 + after + 31])\n",
    "        if found != []:\n",
    "            res.append(\"#### \" + t)\n",
    "            res += found\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def korpus_konk(phrase, korpus, before = 10, after = 10):\n",
    "    actual_konk = konk(phrase, korpus)\n",
    "    result = [\"### Konkordanser for *\" + ' '.join(phrase) + \"*\" ]\n",
    "    for i in actual_konk:\n",
    "        if actual_konk[i] != []:\n",
    "            header = \"#### \" + str(i)\n",
    "            result.append(header)\n",
    "            for hit in actual_konk[i]:\n",
    "                para = hit[0]\n",
    "                parahits = hit[1]\n",
    "                konkstring = []\n",
    "                for y in parahits:\n",
    "                    konkstring.append(str(para) + \": \" + ' '.join(korpus[i][para][y - before : y+after]))\n",
    "                result += konkstring\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epubfile = \"c://users//larsj/Downloads/roolfsen.epub\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "c = make_corpus(epubfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mimetype': [],\n",
       " 'META-INF/container.xml': [],\n",
       " 'OEBPS/content.opf': [],\n",
       " 'OEBPS/Images/MauritsChristopherHansen.jpg': [],\n",
       " 'OEBPS/Images/MordetRoolfsen_tittelblad.jpg': [],\n",
       " 'OEBPS/Styles/style.css': [],\n",
       " 'OEBPS/Text/CoverPage.html': [],\n",
       " 'OEBPS/Text/Section0001.html': [],\n",
       " 'OEBPS/Text/Section0002.html': [],\n",
       " 'OEBPS/Text/Section0003.html': [],\n",
       " 'OEBPS/Text/Section0004.html': [],\n",
       " 'OEBPS/toc.ncx': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
